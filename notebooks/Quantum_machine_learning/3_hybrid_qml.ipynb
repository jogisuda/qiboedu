{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lie-Equivariant Quantum Graph Neural Network (Lie-EQGNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will walk you through an interesting application for hybrid quantum-classical machine learning. Specifically, we will be covering the architecture from the \"[Lie-Equivariant Quantum Graph Neural Network (Lie-EQGNN)](https://arxiv.org/abs/2411.15315)\" paper. There is substantial evidence showing that QML models can suffer from poor trainability and generalization [2,3,4], and a well-known phenomenon that illustrates this is the concentration of measure, also known in the community as barren plateaus. Essentially, high-dimensional functions tend to have their measures concentrated around their mean [5]. This results in a flatter landscape, with gradients going close to zero, making it challenging to locate minima. For QML, this is especially true, since our models generally work in exponentially large Hilbert spaces compared to classical neural networks, for instance. As a consequence, efficiently designing new parameterized circuit architectures is crucial. In this tutorial, we explore a hybrid and symmetry-preserving architecture for an important task in particle physics known as jet tagging. By preserving symmetries, we potentially gain many benefits, like reduced sample and model complexity, and improved generalization bounds - due to an effectively reduced hypothesis space.\n",
    "\n",
    "Below, we begin by importing all the necessary packages, and notice that, for QiBO, we'll be using the PyTorch backend for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Qibo 0.2.18|INFO|2025-06-17 06:43:20]: Using qiboml (pytorch) backend on cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from qibo.symbols import Z, I\n",
    "from qibo.hamiltonians import SymbolicHamiltonian\n",
    "from qiboml.models.encoding import PhaseEncoding\n",
    "from qibo import Circuit, gates, hamiltonians\n",
    "from qiboml.models.decoding import QuantumDecoding\n",
    "from qiboml.interfaces.pytorch import QuantumModel\n",
    "from qibo import set_backend\n",
    "\n",
    "set_backend(\"qiboml\",platform=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset\n",
    "\n",
    "In this work, we consider the task of determining whether a given particle jet originated from a quark or a gluon (this is known as jet-tagging). For illustration we use the high energy physics dataset $\\text{\\textit{Pythia8 Quark and Gluon Jets for Energy Flow}}$ (Patrick T. Komiske et al, 2019), which contains two million jets split equally into one million quark jets and one million gluon jets. These jets resulted from LHC collisions with total center of mass energy $\\sqrt{s} = 14$ TeV and were selected to have transverse momenta $p_T^{jet}$ between $500$ to $550$ GeV and rapidities $|y^{jet}| < 1.7$. For our analysis, we randomly picked $N = 12500$ jets and used the first $10000$ for training, the next $1250$ for validation, and the last $1250$ for testing. These sets happened to contain $4982$, $658$, and $583$ quark jets, respectively.\n",
    "\n",
    "<img src=\"../figures/particle_cloud_mpgan.png\" width=65% style=\"margin-left:auto; margin-right:auto\">\n",
    "\n",
    "*(Figure: the coordinate system (left) used to represent components of the particle momentum $\\vec{p}$. Schematic representation of a gluon jet (middle) and a quark jet (right). The jet constituents (solid lines)  are collimated around the jet axis. [Figure adapted from Fig.~1 in (Raghav Kansal et al, 2021).])*\n",
    "\n",
    "\n",
    "For our purposes, we consider the jet dataset to be constituted of point-clouds, where each jet is represented as a graph $\\mathcal{G} = \\{\\mathcal{V,E}\\}$, i.e., a set of nodes and edges, respectively. (This is the natural data structure used by Graph Neural Networks.) In our case, each node has the transverse momentum $p_T$, pseudorapidity $\\eta$, azimuthal angle $\\phi$ (and other scalar-like quantities like particle ID, particle mass, etc.) of the respective constituent particle in the jet (see the Figure above). Generally, the number of features is always constant, but the number of nodes in each jet may vary. For our analysis we used jets with at least 10 particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to begin loading the jets, we will need some auxiliary functions to handle the graphical format.\n",
    "# Feel free to just run this part and skip to the next section, where the model is defined.\n",
    "\n",
    "def get_adj_matrix(n_nodes, batch_size, edge_mask):\n",
    "    rows, cols = [], []\n",
    "    for batch_idx in range(batch_size):\n",
    "        nn = batch_idx*n_nodes\n",
    "        x = coo_matrix(edge_mask[batch_idx])\n",
    "        rows.append(nn + x.row)\n",
    "        cols.append(nn + x.col)\n",
    "    rows = np.concatenate(rows)\n",
    "    cols = np.concatenate(cols)\n",
    "    edges = [torch.LongTensor(rows), torch.LongTensor(cols)]\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def collate_fn(data):\n",
    "    data = list(zip(*data)) # label p4s nodes atom_mask\n",
    "    data = [torch.stack(item) for item in data]\n",
    "    batch_size, n_nodes, _ = data[1].size()\n",
    "    atom_mask = data[-1]\n",
    "    edge_mask = data[-2]\n",
    "    edges = get_adj_matrix(n_nodes, batch_size, edge_mask)\n",
    "    return data + [edges]\n",
    "\n",
    "\n",
    "def load_jets(p4s, nodes, labels, atom_mask, edge_mask, edges, batch_size, train_ratio, val_ratio, test_ratio):\n",
    "  \n",
    "    # Create a TensorDataset\n",
    "    dataset_all = TensorDataset(labels, p4s, nodes, atom_mask, edge_mask)\n",
    "    \n",
    "    # Calculate the lengths for each split\n",
    "    total_size = len(dataset_all)\n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size = int(total_size * val_ratio)\n",
    "    test_size = total_size - train_size - val_size  # Ensure all data is used\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset_all, [train_size, val_size, test_size])\n",
    "    \n",
    "    # Create a dictionary to hold the datasets\n",
    "    datasets = {\n",
    "        \"train\": train_dataset,\n",
    "        \"val\": val_dataset,\n",
    "        \"test\": test_dataset\n",
    "    }\n",
    "    \n",
    "    dataloaders = {split: DataLoader(dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     pin_memory=False,\n",
    "                                     collate_fn = collate_fn,\n",
    "                                     drop_last=True if (split == 'train') else False,\n",
    "                                     num_workers=0)\n",
    "                        for split, dataset in datasets.items()}\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the jet tagging dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4s = torch.load('../data/p4s.pt')\n",
    "nodes = torch.load('../data/nodes.pt')\n",
    "labels = torch.load('../data/labels.pt')\n",
    "atom_mask = torch.load('../data/atom_mask.pt')\n",
    "edge_mask = torch.from_numpy(np.load('../data/edge_mask.npy'))\n",
    "edges = torch.from_numpy(np.load('../data/edges.npy'))\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "dataloaders = load_jets(p4s, nodes, labels, atom_mask, edge_mask, edges, 16, train_ratio, val_ratio, test_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for jet tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p4s: \ttorch.Size([12500, 3, 4]),\n",
      "nodes: \ttorch.Size([12500, 3, 1]),\n",
      "labels: \ttorch.Size([12500]),\n",
      "atom_mask: \ttorch.Size([12500, 3]), \n",
      "edge_mask: \ttorch.Size([12500, 3, 3]),\n",
      "edges: \ttorch.Size([2, 75000])\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"p4s: \\t{p4s.shape},\n",
    "nodes: \\t{nodes.shape},\n",
    "labels: \\t{labels.shape},\n",
    "atom_mask: \\t{atom_mask.shape}, \n",
    "edge_mask: \\t{edge_mask.shape},\n",
    "edges: \\t{edges.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4s:       4-momentum tensor of particles in each jet sample with shape [n_samples, n_particles, 4] \n",
    "            \n",
    "nodes:     Additional features per particle (e.g., PID or learned embedding), shape [n_samples, n_particles, 1]\n",
    "\n",
    "labels:    Jet-level labels for classification (e.g., quark vs gluon), shape [n_samples]\n",
    "\n",
    "atom_mask: Binary mask indicating which particles are valid (not padding), shape [n_samples, n_particles]\n",
    "\n",
    "edge_mask: Binary mask indicating which particle-pair interactions (edges) are valid, shape [n_samples, n_particles, n_particles]\n",
    "\n",
    "edges:     Edge list for message-passing (graph connectivity), shape [2, n_edges], with each column (src, dst) across all samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quantum and Classical Graph Neural Networks\n",
    "\n",
    "Graph Neural Networks (GNNs) are a class of neural networks designed to operate on graph-structured data. Unlike traditional neural networks that work on Euclidean data such as images or sequences, GNNs are capable of capturing the dependencies and relationships between nodes in a graph. The fundamental idea behind is to iteratively update the representation of each node by aggregating information from its neighbors, thereby enabling the network to learn both local and global graph structures.\n",
    "\n",
    "Given the inherent graph structure of our dataset, which captures the complex interactions and relationships between particles, it is natural to employ graph neural networks (GNNs) for the task of tagging quarks versus gluons. GNNs have been successfully applied in particle physics for such classification tasks, as discussed in the paper \"[Graph Neural Networks in Particle Physics](https://arxiv.org/abs/2007.13681)\" by Shlomi et al. (2020). We start our approach with another classical, symmetry-preserving GNN to establish a foundational understanding and then discuss how we can extend this setting to introduce quantum computing.\n",
    "\n",
    "To start, let $ G = (V, E) $ be a graph where $ V $ is its corresponding, set of nodes and $ E $ is its set of edges. Each node $ v \\in V $ has an initial feature vector $ \\mathbf{h}_v^{(0)} $, which is updated throughout multiple layers of the GNN. At each layer $ l $, the feature vector of the node $ v $ is updated by aggregating the neighboring feature vectors $ \\mathcal{N}(v) $, and then combining them with its own features. The final node representations can be used for various downstream tasks such as node classification, link prediction, or graph classification. The latter is our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A primer to invariance-equivariance constraint\n",
    "\n",
    "As a simple way to illustrate how it is possible to bake a group-equivariance constraint into a GNN, consider a dataset of graphs in which its nodes have cartesian coordinates as inputs features, and let $SO(2)$ - the group of $2D$ rotations - be their underlying symmetry group. Since the Euclidean norm is invariant to rotations, any node-updating function of the form:\n",
    "\n",
    "\\begin{equation}\n",
    "    x_{i}^{l+1} = x_{i}^{l} + C\\sum_{j\\in \\mathcal{N}(i)} (x_{i}^{l} - x_{j}^{l})\\;\\phi_x (m_{ij}^{l})\n",
    "\\end{equation}\n",
    "\n",
    "is naturally equivariant, where $\\phi_x$ can be a classical neural network, and $m_{ij}^{l}$ is the edge message between nodes $i$ and $j$ in layer $l$. To see why equivariance holds in this case, we just need to see that, for any arbitrary rotation matrix $R$:\n",
    "\n",
    "\\begin{align}\n",
    "    R x_{i}^{l+1} &= R x_{i}^{l} + C\\sum_{j\\in \\mathcal{N}(i)} (R x_{i}^{l} - R x_{j}^{l})\\;\\phi_x (m_{ij}^{l})\\\\\n",
    "    &= R x_{i}^{l} + C\\sum_{j\\in \\mathcal{N}(i)} R (x_{i}^{l} - x_{j}^{l})\\;\\phi_x (m_{ij}^{l})\\\\\n",
    "    &= R(x_{i}^{l} + C\\sum_{j\\in \\mathcal{N}(i)}(x_{i}^{l} - x_{j}^{l})\\;\\phi_x (m_{ij}^{l}) )\n",
    "\\end{align}\n",
    "\n",
    "This means that applying a rotation from the inside, directly transforming the data points (nodes), and then updating their coordinate, is equivalent to applying a rotation from the outside, that is, first updating their coordinate, and then acting with the group. The equation above implies that $m_{ij}^{l}$ also needs to be invariant, which can be achieved by having its inputs also being invariant measures,  like the euclidean norm given above and the standard dot-product, since $\\langle x, y\\rangle = \\langle Rx, Ry\\rangle$; it is easy to check, then, that equivariance breaks on the contrary. In the next section, we show how using a very similar formulation allows us to preserve the Lorentz group, a key symmetry in all of relativistic quantum field theory and inherent to almost all tasks involving high-energy particle scattering experiments, like we do in the Large Hadron Collider (LHC), at CERN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LorentzNet\n",
    "The first Lorentz-group preserving architecture we shall see is a very well known one in the particle physics community, called **LorentzNet** ([arXiv:2201.08187](https://arxiv.org/abs/2201.08187)). This is going to be a classical model, and through the course of this tutorial we'll understand where to fit in quantum computing, which will be the heart of our approach. Before any quantum, let's see what this classical model is doing first. The whole idea is to preserve the group actions by using universally-approximating Lorentz-equivariant polynomials, which will be responsible for the message passing scheme, and also updating the particle scalar and four-momentum latent representations. We can illustrate it as follows:\n",
    "\n",
    "<center>\n",
    "<img src=\"../figures/LorentzNet.png\" width=\"65%\" style=\"margin-left:auto; margin-right:auto\">\n",
    "</center>\n",
    "\n",
    "*(Figure: Schematic representation of the LorentzNet architecture.)*\n",
    "\n",
    "\n",
    "From the beginning, the **input** here consists of a concatenation of four-momentum vectors (called just particle coordinates from now on) and additional scalar features, like color, charge, flavor, etc. The combined feature vector for each particle (node) is:\n",
    "\n",
    "$$\n",
    "f_i = v_i \\oplus s_i,\n",
    "$$\n",
    "\n",
    "where $\\oplus$ denotes concatenation. Next, we turn to the core building block of this architecture:\n",
    "\n",
    "**Lorentz Group Equivariant Block (LGEB)**\n",
    "\n",
    "This is where the node and edge features are updated while preserving the Lorentz equivariance. The key components are symmetry-preserving functions for updating the coordinate, scalar and edge message features. Let's check:\n",
    "\n",
    "1. **Invariant Edge Message Function $\\phi_e$**:\n",
    "   - Computes messages passed between particles.\n",
    "   - Captures pairwise interactions and relativistic geometrical relationships.\n",
    "   - Depends on Lorentz-invariant scalars, hence the edge message is invariant.\n",
    "     \n",
    "2. **Equivariant Coordinate Update Function $\\phi_x$**:\n",
    "   - Updates the coordinate embeddings of particles.\n",
    "   - Incorporates attention mechanisms respecting Minkowski spacetime.\n",
    "   - Ensures Lorentz-equivariance in its definition.\n",
    "     \n",
    "3. **Invariant Scalar Feature Update Function $\\phi_h$**:\n",
    "   - Updates scalar features of particles.\n",
    "   - Aggregates information from neighboring particles.\n",
    "   - Again, depends on Lorentz-invariant scalar features, so it is also invariant.\n",
    "     \n",
    "These functions are modeled using neural networks capable of approximating continuous functions. Here, in each $\\phi$, we are going to introduce quantum neural networks to add more expressivity to the mix. Since QNNs are also universal approximators, we are good to go.\n",
    "\n",
    "## 3.3. Detailed Formulation\n",
    "\n",
    "1. **Edge Message Computation $\\phi_e$**:\n",
    "\n",
    "   For particles $i$ and $j$ at layer $l$, the **edge message** $m_{ij}^{l}$ is computed as:\n",
    "\n",
    "   $$\n",
    "   m_{ij}^{l} = \\phi_e \\left( h_i^{l}, h_j^{l}, \\psi\\left( \\| x_i^{l} - x_j^{l} \\|^2 \\right), \\psi\\left( \\langle x_i^{l}, x_j^{l} \\rangle \\right) \\right),\n",
    "   $$\n",
    "\n",
    "   where:\n",
    "\n",
    "   - $h_i^{l}$ and $h_j^{l}$ are the scalar features of particles $i$ and $j$ at layer $l$.\n",
    "   - $x_i^{l}$ and $x_j^{l}$ are the coordinate embeddings (four-vectors) at layer $l$.\n",
    "   - $\\| x_i^{l} - x_j^{l} \\|^2$ is the squared Minkowski **distance** between particles $i$ and $j$.\n",
    "   - $\\langle x_i^{l}, x_j^{l} \\rangle$ is the Minkowski **inner product** (Lorentz dot product).\n",
    "   - $\\psi(\\cdot)$ is a normalization function to help stabilize the gradients due to large numbers, and is defined in the paper as:\n",
    "\n",
    "     $$\n",
    "     \\psi(a) = \\operatorname{sgn}(a) \\cdot \\log\\left( |a| + 1 \\right),\n",
    "     $$\n",
    "\n",
    "     with $\\operatorname{sgn}(a)$ being the sign function.\n",
    "\n",
    "2. **Coordinate Embedding Update $\\phi_x$**:\n",
    "\n",
    "   The **coordinate embeddings** of particles are updated by a neighborhood-dependent equivariant function:\n",
    "\n",
    "   $$\n",
    "   x_i^{l+1} = x_i^{l} + c \\sum_{j \\in \\mathcal{N}(i)} \\phi_x ( m_{ij}^{l}) \\cdot x_j^{l},\n",
    "   $$\n",
    "\n",
    "   where:\n",
    "\n",
    "   - $\\mathcal{N}(i)$ denotes the **neighborhood** of particle $i$, i.e., particles connected to $i$ in the graph.\n",
    "   - $c$ is a scaling constant controlling the update magnitude.\n",
    "   - $\\phi_x ( m_{ij}^{l})$ computes an **attention weight** based on the edge message $m_{ij}^{l}$.\n",
    "\n",
    "\n",
    "3. **Scalar Feature Update $\\phi_h$**:\n",
    "\n",
    "   Finally, the **scalar features** are updated as:\n",
    "\n",
    "   $$\n",
    "   h_i^{l+1} = h_i^{l} + \\phi_h \\left( h_i^{l}, \\sum_{j \\in \\mathcal{N}(i)} w_{ij}^{l} m_{ij}^{l} \\right),\n",
    "   $$\n",
    "\n",
    "   where:\n",
    "\n",
    "   - $w_{ij}^{l}$ is an **edge significance weight** calculated by:\n",
    "\n",
    "     $$\n",
    "     w_{ij}^{l} = \\phi_m \\left( m_{ij}^{l} \\right) \\in [0, 1],\n",
    "     $$\n",
    "\n",
    "     with $\\phi_m$ being a neural network outputting values in the range [0, 1].\n",
    "\n",
    "   - $\\phi_h$ aggregates information from neighboring particles to update $h_i^{l}$.\n",
    "\n",
    "The purpose of $w_{ij}^{l}$ is to learn the importance of the edge connecting particles $i$ and $j$, and $\\phi_h$ integrates these weighted messages to refine the scalar features, so our model can potentially learn more complex interactions.\n",
    "\n",
    "A noteworthy aspect of LorentzNet is its approach to handling outputs: although both **coordinate embeddings** $x_i^{l}$ and **scalar features** $h_i^{l}$ are updated through the layers, the final output only uses the **scalar features** $h_i^{L}$ from the last layer $L$. This strategy reduces redundancy and computational overhead because the edge messages $m_{ij}^{l}$ already incorporate information from both $x_i^{l}$ and $x_j^{l}$.\n",
    "      \n",
    "**Implementation Details**\n",
    "\n",
    "To ensure fidelity with the original LorentzNet architecture and leverage existing optimizations, we utilize the official implementation provided by the authors:\n",
    "\n",
    "- **Repository**: [LorentzNet-release](https://github.com/sdogsq/LorentzNet-release/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define our parameterized circuits.\n",
    "\n",
    "In order to measure multiple observables and perform gradient descent afterwards, the first thing that we'll need is to define a CustomDecoder. Before anything else, let's also define an auxiliary function to create a list of observables of the form\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Observables }=[\\hat{\\sigma}_z &\\otimes \\mathbb{I} \\otimes \\mathbb{I} \\otimes \\cdots \\otimes \\mathbb{I},\\\\\n",
    "\\mathbb{I} &\\otimes \\hat{\\sigma}_z \\otimes \\mathbb{I} \\otimes \\cdots \\otimes \\mathbb{I},\\\\\n",
    "\\mathbb{I} &\\otimes \\mathbb{I} \\otimes \\hat{\\sigma}_z \\otimes \\cdots \\otimes \\mathbb{I},\\\\\n",
    "\\mathbb{I} &\\otimes \\mathbb{I} \\otimes \\mathbb{I} \\otimes \\cdots \\otimes \\hat{\\sigma}_z]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hamiltonians(n_qubits):\n",
    "\n",
    "    measurements = []\n",
    "    for i in range(n_qubits):\n",
    "        hamiltonians = [I(i) for i in range(n_qubits)]\n",
    "        hamiltonians[i] = Z(i)\n",
    "    \n",
    "        H = 1\n",
    "        for term in hamiltonians:\n",
    "            H *= term\n",
    "            \n",
    "        H = SymbolicHamiltonian(H)\n",
    "        measurements.append(H)\n",
    "    \n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecoderMultipleZ(QuantumDecoding):\n",
    "\n",
    "    def __init__(self, nqubits: int):\n",
    "        super().__init__(nqubits)\n",
    "        # build the observables using qibo's SymbolicHamiltonian\n",
    "        self.nqubits = nqubits\n",
    "        self.hamilts = create_hamiltonians(nqubits)\n",
    "\n",
    "    def __call__(self, x: Circuit):\n",
    "        # execute the circuit and collect the final state\n",
    "        state = super().__call__(x).state()\n",
    "\n",
    "        # collect expectation values (each one must be a torch Tensor!)\n",
    "        expvals = [self.hamilts[i].expectation(state)        # scalar tensor\n",
    "                   for i in range(self.nqubits)]\n",
    "\n",
    "        # stack them without breaking the graph\n",
    "        return torch.stack(expvals)      # shape (nqubits,)\n",
    "        \n",
    "    # specify the shape of the output\n",
    "    @property\n",
    "    def output_shape(self) -> tuple[int]:\n",
    "        return (self.nqubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_quantum_net(n_qubits, nlayers):\n",
    "\n",
    "    qubits = list(range(n_qubits))\n",
    "    \n",
    "    # define the encoding\n",
    "    encoding = PhaseEncoding(nqubits=n_qubits)\n",
    "\n",
    "    # build the computation circuit\n",
    "    circuit = Circuit(n_qubits)\n",
    "\n",
    "    decoding = CustomDecoderMultipleZ(n_qubits)\n",
    "    \n",
    "    circuit.add(gates.H(q) for q in qubits)\n",
    "    for layer in range(nlayers):\n",
    "        for q in qubits:\n",
    "            circuit.add(gates.RY(q, theta=torch.randn(1) * np.pi, trainable=True)) # random.random()\n",
    "            circuit.add(gates.RZ(q, theta=torch.randn(1) * np.pi, trainable=True))\n",
    "\n",
    "        if n_qubits > 1:\n",
    "            for i, q in enumerate(qubits[:-2]):\n",
    "                circuit.add(gates.CNOT(q0=q, q1=qubits[i + 1]))\n",
    "            circuit.add(gates.CNOT(q0=qubits[-1], q1=qubits[0]))\n",
    "\n",
    "    return encoding, circuit, decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Some auxiliary functions\"\"\"\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Speed of light (m/s)\n",
    "c = 299792458\n",
    "\n",
    "\"\"\"Lorentz transformations describe the transition between two inertial reference\n",
    "frames F and F', each of which is moving in some direction with respect to the\n",
    "other. This code only calculates Lorentz transformations for movement in the x\n",
    "direction with no spatial rotation (i.e., a Lorentz boost in the x direction).\n",
    "The Lorentz transformations are calculated here as linear transformations of\n",
    "four-vectors [ct, x, y, z] described by Minkowski space. Note that t (time) is\n",
    "multiplied by c (the speed of light) in the first entry of each four-vector.\n",
    "\n",
    "Thus, if X = [ct; x; y; z] and X' = [ct'; x'; y'; z'] are the four-vectors for\n",
    "two inertial reference frames and X' moves in the x direction with velocity v\n",
    "with respect to X, then the Lorentz transformation from X to X' is X' = BX,\n",
    "where\n",
    "\n",
    "    | γ  -γβ  0  0|\n",
    "B = |-γβ  γ   0  0|\n",
    "    | 0   0   1  0|\n",
    "    | 0   0   0  1|\n",
    "\n",
    "is the matrix describing the Lorentz boost between X and X',\n",
    "γ = 1 / √(1 - v²/c²) is the Lorentz factor, and β = v/c is the velocity as\n",
    "a fraction of c.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def beta(velocity: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculates β = v/c, the given velocity as a fraction of c\n",
    "    >>> beta(c)\n",
    "    1.0\n",
    "    >>> beta(199792458)\n",
    "    0.666435904801848\n",
    "    \"\"\"\n",
    "    if velocity > c:\n",
    "        raise ValueError(\"Speed must not exceed light speed 299,792,458 [m/s]!\")\n",
    "    elif velocity < 1:\n",
    "        # Usually the speed should be much higher than 1 (c order of magnitude)\n",
    "        raise ValueError(\"Speed must be greater than or equal to 1!\")\n",
    "\n",
    "    return velocity / c\n",
    "\n",
    "\n",
    "def gamma(velocity: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Lorentz factor γ = 1 / √(1 - v²/c²) for a given velocity\n",
    "    >>> gamma(4)\n",
    "    1.0000000000000002\n",
    "    >>> gamma(1e5)\n",
    "    1.0000000556325075\n",
    "    >>> gamma(3e7)\n",
    "    1.005044845777813\n",
    "    >>> gamma(2.8e8)\n",
    "    2.7985595722318277\n",
    "    \"\"\"\n",
    "    return 1 / sqrt(1 - beta(velocity) ** 2)\n",
    "\n",
    "\n",
    "def transformation_matrix(velocity: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the Lorentz transformation matrix for movement in the x direction:\n",
    "\n",
    "    | γ  -γβ  0  0|\n",
    "    |-γβ  γ   0  0|\n",
    "    | 0   0   1  0|\n",
    "    | 0   0   0  1|\n",
    "\n",
    "    where γ is the Lorentz factor and β is the velocity as a fraction of c\n",
    "    >>> transformation_matrix(29979245)\n",
    "    array([[ 1.00503781, -0.10050378,  0.        ,  0.        ],\n",
    "           [-0.10050378,  1.00503781,  0.        ,  0.        ],\n",
    "           [ 0.        ,  0.        ,  1.        ,  0.        ],\n",
    "           [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "    \"\"\"\n",
    "    return np.array(\n",
    "        [\n",
    "            [gamma(velocity), -gamma(velocity) * beta(velocity), 0, 0],\n",
    "            [-gamma(velocity) * beta(velocity), gamma(velocity), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def unsorted_segment_sum(data, segment_ids, num_segments):\n",
    "    r'''Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`.\n",
    "    Adapted from https://github.com/vgsatorras/egnn.\n",
    "    '''\n",
    "    result = data.new_zeros((num_segments, data.size(1)))\n",
    "    result.index_add_(0, segment_ids, data)\n",
    "    return result\n",
    "\n",
    "def unsorted_segment_mean(data, segment_ids, num_segments):\n",
    "    r'''Custom PyTorch op to replicate TensorFlow's `unsorted_segment_mean`.\n",
    "    Adapted from https://github.com/vgsatorras/egnn.\n",
    "    '''\n",
    "    result = data.new_zeros((num_segments, data.size(1)))\n",
    "    count = data.new_zeros((num_segments, data.size(1)))\n",
    "    result.index_add_(0, segment_ids, data)\n",
    "    count.index_add_(0, segment_ids, torch.ones_like(data))\n",
    "    return result / count.clamp(min=1)\n",
    "\n",
    "def normsq4(p):\n",
    "    r''' Minkowski square norm\n",
    "         `\\|p\\|^2 = p[0]^2-p[1]^2-p[2]^2-p[3]^2`\n",
    "    ''' \n",
    "    psq = torch.pow(p, 2)\n",
    "    return 2 * psq[..., 0] - psq.sum(dim=-1)\n",
    "    \n",
    "def dotsq4(p,q):\n",
    "    r''' Minkowski inner product\n",
    "         `<p,q> = p[0]q[0]-p[1]q[1]-p[2]q[2]-p[3]q[3]`\n",
    "    '''\n",
    "    psq = p*q\n",
    "    return 2 * psq[..., 0] - psq.sum(dim=-1)\n",
    "\n",
    "def normA_fn(A):\n",
    "    return lambda p: torch.einsum('...i, ij, ...j->...', p, A, p)\n",
    "\n",
    "def dotA_fn(A):\n",
    "    return lambda p, q: torch.einsum('...i, ij, ...j->...', p, A, q)\n",
    "    \n",
    "def psi(p):\n",
    "    ''' `\\psi(p) = Sgn(p) \\cdot \\log(|p| + 1)`\n",
    "    '''\n",
    "    return torch.sign(p) * torch.log(torch.abs(p) + 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "def makedir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "def args_init(args):\n",
    "    r''' Initialize seed and exp_name.\n",
    "    '''\n",
    "    if args.seed is None: # use random seed if not specified\n",
    "        args.seed = np.random.randint(100)\n",
    "    if args.exp_name == '': # use random strings if not specified\n",
    "        args.exp_name = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "    if (args.local_rank == 0): # master\n",
    "        print(args)\n",
    "        makedir(f\"{args.logdir}/{args.exp_name}\")\n",
    "        with open(f\"{args.logdir}/{args.exp_name}/args.json\", 'w') as f:\n",
    "            json.dump(args.__dict__, f, indent=4)\n",
    "\n",
    "def sum_reduce(num, device):\n",
    "    r''' Sum the tensor across the devices.\n",
    "    '''\n",
    "    if not torch.is_tensor(num):\n",
    "        rt = torch.tensor(num).to(device)\n",
    "    else:\n",
    "        rt = num.clone()\n",
    "    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n",
    "    return rt\n",
    "\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class GradualWarmupScheduler(_LRScheduler):\n",
    "    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n",
    "    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n",
    "        warmup_epoch: target learning rate is reached at warmup_epoch, gradually\n",
    "        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n",
    "    Reference:\n",
    "        https://github.com/ildoonet/pytorch-gradual-warmup-lr\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, multiplier, warmup_epoch, after_scheduler=None):\n",
    "        self.multiplier = multiplier\n",
    "        if self.multiplier < 1.:\n",
    "            raise ValueError('multiplier should be greater thant or equal to 1.')\n",
    "        self.warmup_epoch = warmup_epoch\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super(GradualWarmupScheduler, self).__init__(optimizer)\n",
    "\n",
    "    @property\n",
    "    def _warmup_lr(self):\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch + 1) / self.warmup_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * (self.last_epoch + 1) / self.warmup_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch >= self.warmup_epoch - 1:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_last_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "\n",
    "        return self._warmup_lr\n",
    "\n",
    "    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n",
    "        self.last_epoch = self.last_epoch + 1 if epoch==None else epoch\n",
    "        if self.last_epoch >= self.warmup_epoch - 1:\n",
    "            if not self.finished:\n",
    "                warmup_lr = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n",
    "                    param_group['lr'] = lr\n",
    "                self.finished = True\n",
    "                return\n",
    "            if epoch is None:\n",
    "                self.after_scheduler.step(metrics, None)\n",
    "            else:\n",
    "                self.after_scheduler.step(metrics, epoch - self.warmup_epoch)\n",
    "            return\n",
    "\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self._warmup_lr):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def step(self, epoch=None, metrics=None):\n",
    "        if type(self.after_scheduler) != ReduceLROnPlateau:\n",
    "            if self.finished and self.after_scheduler:\n",
    "                if epoch is None:\n",
    "                    self.after_scheduler.step(None)\n",
    "                else:\n",
    "                    self.after_scheduler.step(epoch - self.warmup_epoch)\n",
    "                self.last_epoch = self.after_scheduler.last_epoch + self.warmup_epoch + 1\n",
    "                self._last_lr = self.after_scheduler.get_last_lr()\n",
    "            else:\n",
    "                return super(GradualWarmupScheduler, self).step(epoch)\n",
    "        else:\n",
    "            self.step_ReduceLROnPlateau(metrics, epoch)\n",
    "\n",
    "        self._last_lr = [group['lr'] for group in self.optimizer.param_groups]\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the state of the scheduler as a :class:`dict`.\n",
    "\n",
    "        It contains an entry for every variable in self.__dict__ which\n",
    "        is not the optimizer.\n",
    "        \"\"\"\n",
    "        result = {key: value for key, value in self.__dict__.items() if key != 'optimizer' or key != \"after_scheduler\"}\n",
    "        if self.after_scheduler:\n",
    "            result.update({\"after_scheduler\": self.after_scheduler.state_dict()})\n",
    "        return result\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        after_scheduler_state = state_dict.pop(\"after_scheduler\", None)\n",
    "        self.__dict__.update(state_dict)\n",
    "        if after_scheduler_state:\n",
    "            self.after_scheduler.load_state_dict(after_scheduler_state)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "def buildROC(labels, score, targetEff=[0.3,0.5]):\n",
    "    r''' ROC curve is a plot of the true positive rate (Sensitivity) in the function of the false positive rate\n",
    "    (100-Specificity) for different cut-off points of a parameter. Each point on the ROC curve represents a\n",
    "    sensitivity/specificity pair corresponding to a particular decision threshold. The Area Under the ROC\n",
    "    curve (AUC) is a measure of how well a parameter can distinguish between two diagnostic groups.\n",
    "    '''\n",
    "    if not isinstance(targetEff, list):\n",
    "        targetEff = [targetEff]\n",
    "    fpr, tpr, threshold = roc_curve(labels, score)\n",
    "    idx = [np.argmin(np.abs(tpr - Eff)) for Eff in targetEff]\n",
    "    eB, eS = fpr[idx], tpr[idx]\n",
    "    return fpr, tpr, threshold, eB, eS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "    Quantum Lie-Equivariant Group Block (QLieGEB).\n",
    "    \n",
    "        - Given the Lie generators found (i.e.: through LieGAN, oracle-preserving latent flow, or some other approach\n",
    "          that we develop further), once the metric tensor J is found via the equation:\n",
    "\n",
    "                          L.J + J.(L^T) = 0,\n",
    "                          \n",
    "          we just have to specify the metric to make the model symmetry-preserving to the corresponding Lie group. \n",
    "          In the cells below, I will show first how the model preserves symmetries (starting with the default Lorentz group),\n",
    "          and when we change J to some other metric (Euclidean, for example), Lorentz boosts break equivariance, while other\n",
    "          transformations preserve it (rotations, for the example shown in the cells below)\n",
    "\"\"\"\n",
    "class QLieGEB(nn.Module):\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_node_attr=0,\n",
    "                 dropout = 0., c_weight=1.0, last_layer=False, A=None, include_x=False, \n",
    "                 model_type='classical', nlayers_qnn = 4, device='cpu'):\n",
    "        \n",
    "        super(QLieGEB, self).__init__()\n",
    "        self.c_weight = c_weight\n",
    "        self.model_type = model_type\n",
    "        n_edge_attr = 2 if not include_x else 10 # dims for Minkowski norm & inner product\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.include_x = include_x\n",
    "\n",
    "        \"\"\"\n",
    "            phi_e: input size: n_qubits -> output size: n_qubits\n",
    "            n_hidden has to be equal to n_input (n_input * 2 + n_edge_attr),\n",
    "            but this is just considering that this is a simple working example.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        self.n_hidden = n_input * 2 + n_edge_attr\n",
    "        \n",
    "        if model_type in ['phi_e', 'quantum']:\n",
    "\n",
    "            n_qubits=n_input * 2 + n_edge_attr\n",
    "\n",
    "            self.n_output_e = self.n_hidden\n",
    "            \n",
    "            encoding, circuit, decoding = create_quantum_net(n_qubits, \n",
    "                                                             nlayers_qnn)\n",
    "            q_circuit_e = QuantumModel([encoding, circuit], decoding)\n",
    "\n",
    "            self.phi_e = nn.Sequential(q_circuit_e,\n",
    "                                      nn.Linear(n_qubits, self.n_hidden),\n",
    "                                      nn.ReLU())\n",
    "            self.BatchNorm1d_e = nn.BatchNorm1d(self.n_hidden)\n",
    "        else:\n",
    "            self.phi_e = nn.Sequential(\n",
    "                        nn.Linear(n_input * 2 + n_edge_attr, self.n_hidden, bias=False),\n",
    "                        nn.BatchNorm1d(self.n_hidden),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                        nn.ReLU()).float()\n",
    "            \n",
    "\n",
    "        if model_type in ['phi_h', 'quantum']:\n",
    "            \n",
    "            n_qubits=self.n_hidden\n",
    "            \n",
    "            self.n_output_h = n_output\n",
    "            \n",
    "            encoding, circuit, decoding = create_quantum_net(n_qubits, \n",
    "                                                             nlayers_qnn)\n",
    "            q_circuit_h = QuantumModel([encoding, circuit], decoding)\n",
    "\n",
    "            self.phi_h = nn.Sequential(nn.Linear(self.n_hidden + n_input + n_node_attr, self.n_hidden, bias=False),\n",
    "                                       # nn.BatchNorm1d(n_hidden),\n",
    "                                       nn.ReLU(),\n",
    "                                       q_circuit_h,\n",
    "                                       nn.Linear(n_qubits, n_output))\n",
    "\n",
    "            \n",
    "            self.BatchNorm1d_h = nn.BatchNorm1d(4)\n",
    "            \n",
    "        else:\n",
    "            self.phi_h = nn.Sequential(\n",
    "                nn.Linear(self.n_hidden + n_input + n_node_attr, self.n_hidden),\n",
    "                nn.BatchNorm1d(self.n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.n_hidden, n_output))\n",
    "\n",
    "        \n",
    "\n",
    "        if model_type in ['phi_x', 'quantum']:\n",
    "            down_projection = nn.Linear(self.n_hidden, 1, bias=False)\n",
    "            torch.nn.init.xavier_uniform_(down_projection.weight, gain=0.001)\n",
    "\n",
    "            n_qubits=self.n_hidden\n",
    "            encoding, circuit, decoding = create_quantum_net(n_qubits, \n",
    "                                                             nlayers_qnn)\n",
    "            q_circuit_x = QuantumModel([encoding, circuit], decoding)\n",
    "\n",
    "            self.phi_x = nn.Sequential(q_circuit_x,\n",
    "                                       down_projection)\n",
    "            #down_projection is removed for now since we currently only\n",
    "            # measure one observable at a time.\n",
    "                        \n",
    "        else:\n",
    "            layer = nn.Linear(self.n_hidden, 1, bias=False)\n",
    "            torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
    "            self.phi_x = nn.Sequential(\n",
    "                nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                nn.ReLU(),\n",
    "                layer)\n",
    "\n",
    "        \n",
    "        if model_type in ['phi_m', 'quantum']:\n",
    "\n",
    "            n_qubits=1\n",
    "            encoding, circuit, decoding = create_quantum_net(n_qubits, \n",
    "                                                             nlayers_qnn,)\n",
    "            q_circuit_m = QuantumModel([encoding, circuit], decoding)\n",
    "\n",
    "            self.phi_m = nn.Sequential(nn.Linear(self.n_hidden, 1),\n",
    "                                       nn.ReLU(),\n",
    "                                       q_circuit_m)\n",
    "        else:\n",
    "            self.phi_m = nn.Sequential(\n",
    "                nn.Linear(self.n_hidden, 1),\n",
    "                nn.Sigmoid())    \n",
    "\n",
    "        \n",
    "        self.last_layer = last_layer\n",
    "        if last_layer:\n",
    "            del self.phi_x\n",
    "\n",
    "        self.A = A\n",
    "        self.norm_fn = normA_fn(A) if A is not None else normsq4\n",
    "        self.dot_fn = dotA_fn(A) if A is not None else dotsq4\n",
    "\n",
    "    def m_model(self, hi, hj, norms, dots):\n",
    "        out = torch.cat([hi, hj, norms, dots], dim=1)\n",
    "\n",
    "        if self.model_type in [\"phi_e\", \"quantum\"]:\n",
    "            out2 = torch.empty(0, self.n_output_e).to(self.device)\n",
    "            for x in out:\n",
    "                out2 = torch.cat((out2, self.phi_e(x).unsqueeze(0).to(self.device)) )\n",
    "    \n",
    "            out = self.BatchNorm1d_e(out2)\n",
    "        \n",
    "        w = self.phi_m(out)\n",
    "        out = out * w\n",
    "        return out\n",
    "\n",
    "    def m_model_extended(self, hi, hj, norms, dots, xi, xj):\n",
    "        out = torch.cat([hi, hj, norms, dots, xi, xj], dim=1)\n",
    "        out = self.phi_e(out).squeeze(0)\n",
    "        w = self.phi_m(out)\n",
    "        out = out * w\n",
    "        return out\n",
    "\n",
    "    def h_model(self, h, edges, m, node_attr):\n",
    "        i, j = edges\n",
    "        agg = unsorted_segment_sum(m, i, num_segments=h.size(0))\n",
    "        agg = torch.cat([h, agg, node_attr], dim=1)\n",
    "\n",
    "\n",
    "        if self.model_type in [\"phi_h\", \"quantum\"]:\n",
    "            out = torch.empty(0, self.n_output_h).to(self.device)\n",
    "            for x in agg:\n",
    "                out = torch.cat((out, self.phi_h(x).unsqueeze(0).to(self.device)) )\n",
    "            out = self.BatchNorm1d_h(out)\n",
    "            out = h + out\n",
    "        else:\n",
    "            out = h + self.phi_h(agg)\n",
    "            \n",
    "        return out\n",
    "\n",
    "    def x_model(self, x, edges, x_diff, m):\n",
    "        i, j = edges\n",
    "        \n",
    "        # trans = x_diff * out\n",
    "        trans = x_diff * self.phi_x(m)\n",
    "        # From https://github.com/vgsatorras/egnn\n",
    "        # This is never activated but just in case it explosed it may save the train\n",
    "        trans = torch.clamp(trans, min=-100, max=100)\n",
    "        agg = unsorted_segment_mean(trans, i, num_segments=x.size(0))\n",
    "        x = x + agg * self.c_weight\n",
    "        return x\n",
    "\n",
    "    def minkowski_feats(self, edges, x):\n",
    "        i, j = edges\n",
    "        x_diff = x[i] - x[j]\n",
    "        norms = self.norm_fn(x_diff).unsqueeze(1)\n",
    "        dots = self.dot_fn(x[i], x[j]).unsqueeze(1)\n",
    "        norms, dots = psi(norms), psi(dots)\n",
    "        return norms, dots, x_diff\n",
    "\n",
    "    def forward(self, h, x, edges, node_attr=None):\n",
    "        i, j = edges\n",
    "        norms, dots, x_diff = self.minkowski_feats(edges, x)\n",
    "\n",
    "        if self.include_x:\n",
    "            m = self.m_model_extended(h[i], h[j], norms, dots, x[i], x[j])\n",
    "        else:\n",
    "            m = self.m_model(h[i], h[j], norms, dots) # [B*N, hidden]\n",
    "        if not self.last_layer:\n",
    "            x = self.x_model(x, edges, x_diff, m)\n",
    "        h = self.h_model(h, edges, m, node_attr)\n",
    "        return h, x, m\n",
    "\n",
    "class LieEQGNN(nn.Module):\n",
    "    r''' Implementation of Lie-Equivariant Quantum Graph Neural Network (Lie-EQGNN).\n",
    "\n",
    "    Args:\n",
    "        - `n_scalar` (int): number of input scalars.\n",
    "        - `n_hidden` (int): dimension of latent space.\n",
    "        - `n_class`  (int): number of output classes.\n",
    "        - `n_layers` (int): number of QLieGEB layers.\n",
    "        - `c_weight` (float): weight c in the x_model.\n",
    "        - `dropout`  (float): dropout rate.\n",
    "    '''\n",
    "    def __init__(self, n_scalar, n_hidden, n_class = 2, n_layers = 6, c_weight = 1e-3, dropout = 0., A=None, include_x=False,\n",
    "                model_type='classical', nlayers_qnn = 4, device='cpu'):\n",
    "        \n",
    "        super(LieEQGNN, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Linear(n_scalar, n_hidden)\n",
    "        self.QLieGEBs = nn.ModuleList([QLieGEB(self.n_hidden, self.n_hidden, self.n_hidden, \n",
    "                                    n_node_attr=n_scalar, dropout=dropout,\n",
    "                                    c_weight=c_weight, last_layer=(i==n_layers-1), A=A, include_x=include_x,\n",
    "                                    model_type=model_type, nlayers_qnn = nlayers_qnn, device=device)\n",
    "                                    for i in range(n_layers)])\n",
    "        \n",
    "        self.graph_dec = nn.Sequential(nn.Linear(self.n_hidden, self.n_hidden),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(dropout),\n",
    "                                       nn.Linear(self.n_hidden, n_class)) # classification\n",
    "\n",
    "    def forward(self, scalars, x, edges, node_mask, edge_mask, n_nodes, show_embeddings=False):\n",
    "        h = self.embedding(scalars)\n",
    "\n",
    "        if show_embeddings:\n",
    "            print(\"Scalar embedding, h, before (first particle): \\n\", h[0].cpu().detach().numpy())\n",
    "    \n",
    "        for i in range(self.n_layers):\n",
    "            h, x, _ = self.QLieGEBs[i](h, x, edges, node_attr=scalars)\n",
    "\n",
    "        if show_embeddings:\n",
    "            print(\"Scalar embedding, h, after transformation (first particle): \\n\", h[0].cpu().detach().numpy())\n",
    "        \n",
    "        h = h * node_mask\n",
    "        h = h.view(-1, n_nodes, self.n_hidden)\n",
    "        h = torch.mean(h, dim=1)\n",
    "        pred = self.graph_dec(h)\n",
    "        return pred.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invariance-Equivariance analysis\n",
    "\n",
    "Let's start with a default prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, p4s, nodes, atom_mask, edge_mask, edges = next(iter(dataloaders['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float64\n",
    "device = 'cuda'\n",
    "\n",
    "batch_size, n_nodes, _ = p4s.to(device, dtype).size()\n",
    "atom_positions = p4s.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "atom_mask = atom_mask.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "edge_mask = edge_mask.reshape(batch_size * n_nodes * n_nodes, -1).to(device, dtype)\n",
    "nodes = nodes.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "edges = [a.to(device) for a in edges]\n",
    "label = label.to(device, dtype).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jogis\\anaconda3\\envs\\qml_qibo\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1341: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Copy.cpp:307.)\n",
      "  return t.to(\n"
     ]
    }
   ],
   "source": [
    "model = LieEQGNN(n_scalar = 1, n_hidden = 4, n_class = 2,\\\n",
    "                   dropout = 0.2, n_layers = 4,\\\n",
    "                   c_weight = 1e-3, model_type=\"phi_x\", \n",
    "                   nlayers_qnn = 3, device=device).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar embedding, h, before (first particle): \n",
      " [-0.09754075 -0.29659274 -0.30916309 -0.91381201]\n",
      "Scalar embedding, h, after transformation (first particle): \n",
      " [0.53184544 0.06022103 0.80105872 0.03766983]\n"
     ]
    }
   ],
   "source": [
    "pred = model(scalars=nodes, x= atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes, show_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariance-Equivariance analysis \n",
    "\n",
    "* Does taking any random transformation in the four-momentum vectors (i.e.: multiplying by 0.1) preserve our particle's latent representation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar embedding, h, before (first particle): \n",
      " [-0.09754075 -0.29659274 -0.30916309 -0.91381201]\n",
      "Scalar embedding, h, after transformation (first particle): \n",
      " [0.50751093 0.00851223 0.77186386 0.09182914]\n"
     ]
    }
   ],
   "source": [
    "pred = model(scalars=nodes, x= 0.1 * atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes, show_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The logits have changed and we have broken the symmetry. Now, what about the Lorentz transformations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar embedding, h, before (first particle): \n",
      " [-0.09754075 -0.29659274 -0.30916309 -0.91381201]\n",
      "Scalar embedding, h, after transformation (first particle): \n",
      " [0.53184545 0.06022105 0.80105875 0.0376698 ]\n"
     ]
    }
   ],
   "source": [
    "pred = model(scalars=nodes, x= (torch.tensor(transformation_matrix(220000000)).to(device) @ atom_positions.to(device, dtype=torch.float64).T).to(device, dtype=torch.float32).T, edges=edges, node_mask=atom_mask,\n",
    "                     edge_mask=edge_mask, n_nodes=n_nodes, show_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The latent representation is preserved when applying a Lorentz boost to our jet. We are preserving the symmetries!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "Finally, let's train on some data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import json, time\n",
    "import numpy as np\n",
    "# import torch.distributed as dist\n",
    "# from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run(model, epoch, loader, partition, N_EPOCHS=None):\n",
    "    if partition == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    res = {'time':0, 'correct':0, 'loss': 0, 'counter': 0, 'acc': 0,\n",
    "           'loss_arr':[], 'correct_arr':[],'label':[],'score':[]}\n",
    "\n",
    "    tik = time.time()\n",
    "    loader_length = len(loader)\n",
    "\n",
    "    for i, (label, p4s, nodes, atom_mask, edge_mask, edges) in tqdm(enumerate(loader)):\n",
    "        if partition == 'train':\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        batch_size, n_nodes, _ = p4s.size()\n",
    "        atom_positions = p4s.view(batch_size * n_nodes, -1).to(device, dtype)\n",
    "        atom_mask = atom_mask.view(batch_size * n_nodes, -1).to(device)\n",
    "        edge_mask = edge_mask.reshape(batch_size * n_nodes * n_nodes, -1).to(device)\n",
    "        nodes = nodes.view(batch_size * n_nodes, -1).to(device,dtype)\n",
    "        edges = [a.to(device) for a in edges]\n",
    "        label = label.to(device, dtype).long()\n",
    "\n",
    "        pred = model(scalars=nodes, x=atom_positions, edges=edges, node_mask=atom_mask,\n",
    "                         edge_mask=edge_mask, n_nodes=n_nodes)\n",
    "        \n",
    "        predict = pred.max(1).indices\n",
    "        correct = torch.sum(predict == label).item()\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        if partition == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        elif partition == 'test':\n",
    "            # save labels and probilities for ROC / AUC\n",
    "            # print(\"Preds \", pred)\n",
    "            score = torch.nn.functional.softmax(pred, dim = -1)\n",
    "            # print(\"Score test \", score)\n",
    "            # raise\n",
    "            res['label'].append(label)\n",
    "            res['score'].append(score)\n",
    "\n",
    "        res['time'] = time.time() - tik\n",
    "        res['correct'] += correct\n",
    "        res['loss'] += loss.item() * batch_size\n",
    "        res['counter'] += batch_size\n",
    "        res['loss_arr'].append(loss.item())\n",
    "        res['correct_arr'].append(correct)\n",
    "\n",
    "        # if i != 0 and i % args.log_interval == 0:\n",
    "        \n",
    "    running_loss = sum(res['loss_arr'])/len(res['loss_arr'])\n",
    "    running_acc = sum(res['correct_arr'])/(len(res['correct_arr'])*batch_size)\n",
    "    avg_time = res['time']/res['counter'] * batch_size\n",
    "    tmp_counter = res['counter']\n",
    "    tmp_loss = res['loss'] / tmp_counter\n",
    "    tmp_acc = res['correct'] / tmp_counter\n",
    "\n",
    "    if N_EPOCHS:\n",
    "        print(\">> %s \\t Epoch %d/%d \\t Batch %d/%d \\t Loss %.4f \\t Running Acc %.3f \\t Total Acc %.3f \\t Avg Batch Time %.4f\" %\n",
    "             (partition, epoch + 1, N_EPOCHS, i, loader_length, running_loss, running_acc, tmp_acc, avg_time))\n",
    "    else:\n",
    "        print(\">> %s \\t Loss %.4f \\t Running Acc %.3f \\t Total Acc %.3f \\t Avg Batch Time %.4f\" %\n",
    "             (partition, running_loss, running_acc, tmp_acc, avg_time))\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    # ---------- reduce -----------\n",
    "    if partition == 'test':\n",
    "        res['label'] = torch.cat(res['label']).unsqueeze(-1)\n",
    "        res['score'] = torch.cat(res['score'])\n",
    "        res['score'] = torch.cat((res['label'],res['score']),dim=-1)\n",
    "    res['counter'] = res['counter']\n",
    "    res['loss'] = res['loss'] / res['counter']\n",
    "    res['acc'] = res['correct'] / res['counter']\n",
    "    return res\n",
    "\n",
    "def train(model, res, N_EPOCHS, model_path, log_path):\n",
    "    ### training and validation\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_res = run(model, epoch, dataloaders['train'], partition='train', N_EPOCHS = N_EPOCHS)\n",
    "        print(\"Time: train: %.2f \\t Train loss %.4f \\t Train acc: %.4f\" % (train_res['time'],train_res['loss'],train_res['acc']))\n",
    "        # if epoch % args.val_interval == 0:\n",
    "            \n",
    "        # if (args.local_rank == 0):\n",
    "        torch.save(model.state_dict(), os.path.join(model_path, \"checkpoint-epoch-{}.pt\".format(epoch)) )\n",
    "        with torch.no_grad():\n",
    "            val_res = run(model, epoch, dataloaders['val'], partition='val')\n",
    "            \n",
    "        # if (args.local_rank == 0): # only master process save\n",
    "        res['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        res['train_time'].append(train_res['time'])\n",
    "        res['val_time'].append(val_res['time'])\n",
    "        res['train_loss'].append(train_res['loss'])\n",
    "        res['train_acc'].append(train_res['acc'])\n",
    "        res['val_loss'].append(val_res['loss'])\n",
    "        res['val_acc'].append(val_res['acc'])\n",
    "        res['epochs'].append(epoch)\n",
    "\n",
    "        ## save best model\n",
    "        if val_res['acc'] > res['best_val']:\n",
    "            print(\"New best validation model, saving...\")\n",
    "            torch.save(model.state_dict(), os.path.join(model_path,\"best-val-model.pt\"))\n",
    "            res['best_val'] = val_res['acc']\n",
    "            res['best_epoch'] = epoch\n",
    "\n",
    "        print(\"Epoch %d/%d finished.\" % (epoch, N_EPOCHS))\n",
    "        print(\"Train time: %.2f \\t Val time %.2f\" % (train_res['time'], val_res['time']))\n",
    "        print(\"Train loss %.4f \\t Train acc: %.4f\" % (train_res['loss'], train_res['acc']))\n",
    "        print(\"Val loss: %.4f \\t Val acc: %.4f\" % (val_res['loss'], val_res['acc']))\n",
    "        print(\"Best val acc: %.4f at epoch %d.\" % (res['best_val'],  res['best_epoch']))\n",
    "\n",
    "        json_object = json.dumps(res, indent=4)\n",
    "        with open(os.path.join(log_path, \"train-result-epoch{}.json\".format(epoch)), \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "\n",
    "        ## adjust learning rate\n",
    "        if (epoch < 31):\n",
    "            lr_scheduler.step(metrics=val_res['acc'])\n",
    "        else:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = g['lr']*0.5\n",
    "\n",
    "\n",
    "def test(model, res, model_path, log_path):\n",
    "    ### test on best model\n",
    "    best_model = torch.load(os.path.join(model_path, \"best-val-model.pt\"), map_location=device)\n",
    "    model.load_state_dict(best_model)\n",
    "    with torch.no_grad():\n",
    "        test_res = run(model, 0, dataloaders['test'], partition='test')\n",
    "\n",
    "    print(\"Final \", test_res['score'])\n",
    "    pred = test_res['score'].cpu()\n",
    "\n",
    "    np.save(os.path.join(log_path, \"score.npy\"), pred)\n",
    "    fpr, tpr, thres, eB, eS  = buildROC(pred[...,0], pred[...,2])\n",
    "    auc = roc_auc_score(pred[...,0], pred[...,2])\n",
    "\n",
    "    metric = {'test_loss': test_res['loss'], 'test_acc': test_res['acc'],\n",
    "              'test_auc': auc, 'test_1/eB_0.3':1./eB[0],'test_1/eB_0.5':1./eB[1]}\n",
    "    res.update(metric)\n",
    "    print(\"Test: Loss %.4f \\t Acc %.4f \\t AUC: %.4f \\t 1/eB 0.3: %.4f \\t 1/eB 0.5: %.4f\"\\\n",
    "           % (test_res['loss'], test_res['acc'], auc, 1./eB[0], 1./eB[1]))\n",
    "    json_object = json.dumps(res, indent=4)\n",
    "    with open(os.path.join(log_path, \"test-result.json\"), \"w\") as outfile:\n",
    "        outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 503\n",
      " train samples: 10000\n",
      " val samples: 1250\n",
      " test samples: 1250\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:10, 60.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 1/60 \t Batch 624/625 \t Loss 0.7543 \t Running Acc 0.504 \t Total Acc 0.504 \t Avg Batch Time 0.0167\n",
      "Time: train: 10.42 \t Train loss 0.7543 \t Train acc: 0.5038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 91.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.7386 \t Running Acc 3.975 \t Total Acc 0.502 \t Avg Batch Time 0.0014\n",
      "New best validation model, saving...\n",
      "Epoch 0/60 finished.\n",
      "Train time: 10.42 \t Val time 0.87\n",
      "Train loss 0.7543 \t Train acc: 0.5038\n",
      "Val loss: 0.7386 \t Val acc: 0.5024\n",
      "Best val acc: 0.5024 at epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 93.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 2/60 \t Batch 624/625 \t Loss 0.6971 \t Running Acc 0.542 \t Total Acc 0.542 \t Avg Batch Time 0.0107\n",
      "Time: train: 6.72 \t Train loss 0.6971 \t Train acc: 0.5424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 154.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6740 \t Running Acc 4.722 \t Total Acc 0.597 \t Avg Batch Time 0.0008\n",
      "New best validation model, saving...\n",
      "Epoch 1/60 finished.\n",
      "Train time: 6.72 \t Val time 0.51\n",
      "Train loss 0.6971 \t Train acc: 0.5424\n",
      "Val loss: 0.6715 \t Val acc: 0.5968\n",
      "Best val acc: 0.5968 at epoch 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 94.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 3/60 \t Batch 624/625 \t Loss 0.6669 \t Running Acc 0.594 \t Total Acc 0.594 \t Avg Batch Time 0.0106\n",
      "Time: train: 6.63 \t Train loss 0.6669 \t Train acc: 0.5943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 152.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6537 \t Running Acc 4.810 \t Total Acc 0.608 \t Avg Batch Time 0.0008\n",
      "New best validation model, saving...\n",
      "Epoch 2/60 finished.\n",
      "Train time: 6.63 \t Val time 0.52\n",
      "Train loss 0.6669 \t Train acc: 0.5943\n",
      "Val loss: 0.6507 \t Val acc: 0.6080\n",
      "Best val acc: 0.6080 at epoch 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:09, 69.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 4/60 \t Batch 624/625 \t Loss 0.6617 \t Running Acc 0.600 \t Total Acc 0.600 \t Avg Batch Time 0.0145\n",
      "Time: train: 9.04 \t Train loss 0.6617 \t Train acc: 0.6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:01, 69.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6471 \t Running Acc 4.918 \t Total Acc 0.622 \t Avg Batch Time 0.0018\n",
      "New best validation model, saving...\n",
      "Epoch 3/60 finished.\n",
      "Train time: 9.04 \t Val time 1.15\n",
      "Train loss 0.6617 \t Train acc: 0.6001\n",
      "Val loss: 0.6445 \t Val acc: 0.6216\n",
      "Best val acc: 0.6216 at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:09, 63.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 5/60 \t Batch 624/625 \t Loss 0.6600 \t Running Acc 0.606 \t Total Acc 0.606 \t Avg Batch Time 0.0158\n",
      "Time: train: 9.90 \t Train loss 0.6600 \t Train acc: 0.6057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 121.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6476 \t Running Acc 4.905 \t Total Acc 0.620 \t Avg Batch Time 0.0010\n",
      "Epoch 4/60 finished.\n",
      "Train time: 9.90 \t Val time 0.65\n",
      "Train loss 0.6600 \t Train acc: 0.6057\n",
      "Val loss: 0.6447 \t Val acc: 0.6200\n",
      "Best val acc: 0.6216 at epoch 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:12, 51.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 6/60 \t Batch 624/625 \t Loss 0.6590 \t Running Acc 0.604 \t Total Acc 0.604 \t Avg Batch Time 0.0192\n",
      "Time: train: 12.02 \t Train loss 0.6590 \t Train acc: 0.6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 88.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6461 \t Running Acc 4.962 \t Total Acc 0.627 \t Avg Batch Time 0.0014\n",
      "New best validation model, saving...\n",
      "Epoch 5/60 finished.\n",
      "Train time: 12.02 \t Val time 0.90\n",
      "Train loss 0.6590 \t Train acc: 0.6040\n",
      "Val loss: 0.6434 \t Val acc: 0.6272\n",
      "Best val acc: 0.6272 at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:10, 60.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 7/60 \t Batch 624/625 \t Loss 0.6549 \t Running Acc 0.612 \t Total Acc 0.612 \t Avg Batch Time 0.0166\n",
      "Time: train: 10.35 \t Train loss 0.6549 \t Train acc: 0.6119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 92.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6431 \t Running Acc 5.006 \t Total Acc 0.633 \t Avg Batch Time 0.0014\n",
      "New best validation model, saving...\n",
      "Epoch 6/60 finished.\n",
      "Train time: 10.35 \t Val time 0.86\n",
      "Train loss 0.6549 \t Train acc: 0.6119\n",
      "Val loss: 0.6403 \t Val acc: 0.6328\n",
      "Best val acc: 0.6328 at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:11, 54.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 8/60 \t Batch 624/625 \t Loss 0.6544 \t Running Acc 0.614 \t Total Acc 0.614 \t Avg Batch Time 0.0184\n",
      "Time: train: 11.52 \t Train loss 0.6544 \t Train acc: 0.6135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 115.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6420 \t Running Acc 4.975 \t Total Acc 0.629 \t Avg Batch Time 0.0011\n",
      "Epoch 7/60 finished.\n",
      "Train time: 11.52 \t Val time 0.69\n",
      "Train loss 0.6544 \t Train acc: 0.6135\n",
      "Val loss: 0.6392 \t Val acc: 0.6288\n",
      "Best val acc: 0.6328 at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:11, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 9/60 \t Batch 624/625 \t Loss 0.6570 \t Running Acc 0.608 \t Total Acc 0.608 \t Avg Batch Time 0.0181\n",
      "Time: train: 11.31 \t Train loss 0.6570 \t Train acc: 0.6075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:01, 78.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6449 \t Running Acc 5.000 \t Total Acc 0.632 \t Avg Batch Time 0.0016\n",
      "Epoch 8/60 finished.\n",
      "Train time: 11.31 \t Val time 1.01\n",
      "Train loss 0.6570 \t Train acc: 0.6075\n",
      "Val loss: 0.6419 \t Val acc: 0.6320\n",
      "Best val acc: 0.6328 at epoch 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:10, 57.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 10/60 \t Batch 624/625 \t Loss 0.6548 \t Running Acc 0.613 \t Total Acc 0.613 \t Avg Batch Time 0.0174\n",
      "Time: train: 10.89 \t Train loss 0.6548 \t Train acc: 0.6130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 198.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6430 \t Running Acc 5.051 \t Total Acc 0.638 \t Avg Batch Time 0.0006\n",
      "New best validation model, saving...\n",
      "Epoch 9/60 finished.\n",
      "Train time: 10.89 \t Val time 0.40\n",
      "Train loss 0.6548 \t Train acc: 0.6130\n",
      "Val loss: 0.6402 \t Val acc: 0.6384\n",
      "Best val acc: 0.6384 at epoch 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 102.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 11/60 \t Batch 624/625 \t Loss 0.6569 \t Running Acc 0.609 \t Total Acc 0.609 \t Avg Batch Time 0.0098\n",
      "Time: train: 6.10 \t Train loss 0.6569 \t Train acc: 0.6091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 131.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6420 \t Running Acc 4.987 \t Total Acc 0.630 \t Avg Batch Time 0.0010\n",
      "Epoch 10/60 finished.\n",
      "Train time: 6.10 \t Val time 0.60\n",
      "Train loss 0.6569 \t Train acc: 0.6091\n",
      "Val loss: 0.6387 \t Val acc: 0.6304\n",
      "Best val acc: 0.6384 at epoch 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 84.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 12/60 \t Batch 624/625 \t Loss 0.6543 \t Running Acc 0.614 \t Total Acc 0.614 \t Avg Batch Time 0.0118\n",
      "Time: train: 7.37 \t Train loss 0.6543 \t Train acc: 0.6140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:01, 73.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6395 \t Running Acc 5.076 \t Total Acc 0.642 \t Avg Batch Time 0.0017\n",
      "New best validation model, saving...\n",
      "Epoch 11/60 finished.\n",
      "Train time: 7.37 \t Val time 1.08\n",
      "Train loss 0.6543 \t Train acc: 0.6140\n",
      "Val loss: 0.6362 \t Val acc: 0.6416\n",
      "Best val acc: 0.6416 at epoch 11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:09, 64.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 13/60 \t Batch 624/625 \t Loss 0.6526 \t Running Acc 0.619 \t Total Acc 0.619 \t Avg Batch Time 0.0156\n",
      "Time: train: 9.76 \t Train loss 0.6526 \t Train acc: 0.6194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:01, 59.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6376 \t Running Acc 5.095 \t Total Acc 0.644 \t Avg Batch Time 0.0021\n",
      "New best validation model, saving...\n",
      "Epoch 12/60 finished.\n",
      "Train time: 9.76 \t Val time 1.33\n",
      "Train loss 0.6526 \t Train acc: 0.6194\n",
      "Val loss: 0.6346 \t Val acc: 0.6440\n",
      "Best val acc: 0.6440 at epoch 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:08, 73.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 14/60 \t Batch 624/625 \t Loss 0.6546 \t Running Acc 0.615 \t Total Acc 0.615 \t Avg Batch Time 0.0135\n",
      "Time: train: 8.46 \t Train loss 0.6546 \t Train acc: 0.6154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 138.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6359 \t Running Acc 5.127 \t Total Acc 0.648 \t Avg Batch Time 0.0009\n",
      "New best validation model, saving...\n",
      "Epoch 13/60 finished.\n",
      "Train time: 8.46 \t Val time 0.57\n",
      "Train loss 0.6546 \t Train acc: 0.6154\n",
      "Val loss: 0.6329 \t Val acc: 0.6480\n",
      "Best val acc: 0.6480 at epoch 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:10, 62.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 15/60 \t Batch 624/625 \t Loss 0.6511 \t Running Acc 0.620 \t Total Acc 0.620 \t Avg Batch Time 0.0161\n",
      "Time: train: 10.05 \t Train loss 0.6511 \t Train acc: 0.6204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 165.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6349 \t Running Acc 5.165 \t Total Acc 0.653 \t Avg Batch Time 0.0008\n",
      "New best validation model, saving...\n",
      "Epoch 14/60 finished.\n",
      "Train time: 10.05 \t Val time 0.48\n",
      "Train loss 0.6511 \t Train acc: 0.6204\n",
      "Val loss: 0.6320 \t Val acc: 0.6528\n",
      "Best val acc: 0.6528 at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 98.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 16/60 \t Batch 624/625 \t Loss 0.6494 \t Running Acc 0.619 \t Total Acc 0.619 \t Avg Batch Time 0.0102\n",
      "Time: train: 6.36 \t Train loss 0.6494 \t Train acc: 0.6191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 112.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6344 \t Running Acc 5.120 \t Total Acc 0.647 \t Avg Batch Time 0.0011\n",
      "Epoch 15/60 finished.\n",
      "Train time: 6.36 \t Val time 0.70\n",
      "Train loss 0.6494 \t Train acc: 0.6191\n",
      "Val loss: 0.6316 \t Val acc: 0.6472\n",
      "Best val acc: 0.6528 at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:09, 65.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 17/60 \t Batch 624/625 \t Loss 0.6509 \t Running Acc 0.623 \t Total Acc 0.623 \t Avg Batch Time 0.0152\n",
      "Time: train: 9.48 \t Train loss 0.6509 \t Train acc: 0.6233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 104.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6357 \t Running Acc 5.082 \t Total Acc 0.642 \t Avg Batch Time 0.0012\n",
      "Epoch 16/60 finished.\n",
      "Train time: 9.48 \t Val time 0.76\n",
      "Train loss 0.6509 \t Train acc: 0.6233\n",
      "Val loss: 0.6324 \t Val acc: 0.6424\n",
      "Best val acc: 0.6528 at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 96.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 18/60 \t Batch 624/625 \t Loss 0.6508 \t Running Acc 0.625 \t Total Acc 0.625 \t Avg Batch Time 0.0104\n",
      "Time: train: 6.48 \t Train loss 0.6508 \t Train acc: 0.6254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 136.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6349 \t Running Acc 5.114 \t Total Acc 0.646 \t Avg Batch Time 0.0009\n",
      "Epoch 17/60 finished.\n",
      "Train time: 6.48 \t Val time 0.58\n",
      "Train loss 0.6508 \t Train acc: 0.6254\n",
      "Val loss: 0.6314 \t Val acc: 0.6464\n",
      "Best val acc: 0.6528 at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 82.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 19/60 \t Batch 624/625 \t Loss 0.6478 \t Running Acc 0.629 \t Total Acc 0.629 \t Avg Batch Time 0.0122\n",
      "Time: train: 7.60 \t Train loss 0.6478 \t Train acc: 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 189.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6312 \t Running Acc 5.152 \t Total Acc 0.651 \t Avg Batch Time 0.0007\n",
      "Epoch 18/60 finished.\n",
      "Train time: 7.60 \t Val time 0.42\n",
      "Train loss 0.6478 \t Train acc: 0.6291\n",
      "Val loss: 0.6278 \t Val acc: 0.6512\n",
      "Best val acc: 0.6528 at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:08, 71.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 20/60 \t Batch 624/625 \t Loss 0.6458 \t Running Acc 0.630 \t Total Acc 0.630 \t Avg Batch Time 0.0140\n",
      "Time: train: 8.72 \t Train loss 0.6458 \t Train acc: 0.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:01, 70.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6299 \t Running Acc 5.114 \t Total Acc 0.646 \t Avg Batch Time 0.0018\n",
      "Epoch 19/60 finished.\n",
      "Train time: 8.72 \t Val time 1.12\n",
      "Train loss 0.6458 \t Train acc: 0.6305\n",
      "Val loss: 0.6262 \t Val acc: 0.6464\n",
      "Best val acc: 0.6528 at epoch 14.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:08, 77.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 21/60 \t Batch 624/625 \t Loss 0.6461 \t Running Acc 0.632 \t Total Acc 0.632 \t Avg Batch Time 0.0129\n",
      "Time: train: 8.04 \t Train loss 0.6461 \t Train acc: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 177.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6272 \t Running Acc 5.171 \t Total Acc 0.654 \t Avg Batch Time 0.0007\n",
      "New best validation model, saving...\n",
      "Epoch 20/60 finished.\n",
      "Train time: 8.04 \t Val time 0.45\n",
      "Train loss 0.6461 \t Train acc: 0.6324\n",
      "Val loss: 0.6235 \t Val acc: 0.6536\n",
      "Best val acc: 0.6536 at epoch 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 109.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 22/60 \t Batch 624/625 \t Loss 0.6438 \t Running Acc 0.633 \t Total Acc 0.633 \t Avg Batch Time 0.0091\n",
      "Time: train: 5.71 \t Train loss 0.6438 \t Train acc: 0.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 186.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6251 \t Running Acc 5.241 \t Total Acc 0.662 \t Avg Batch Time 0.0007\n",
      "New best validation model, saving...\n",
      "Epoch 21/60 finished.\n",
      "Train time: 5.71 \t Val time 0.43\n",
      "Train loss 0.6438 \t Train acc: 0.6332\n",
      "Val loss: 0.6215 \t Val acc: 0.6624\n",
      "Best val acc: 0.6624 at epoch 21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:10, 62.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 23/60 \t Batch 624/625 \t Loss 0.6420 \t Running Acc 0.630 \t Total Acc 0.630 \t Avg Batch Time 0.0160\n",
      "Time: train: 10.01 \t Train loss 0.6420 \t Train acc: 0.6304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 143.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6211 \t Running Acc 5.241 \t Total Acc 0.662 \t Avg Batch Time 0.0009\n",
      "Epoch 22/60 finished.\n",
      "Train time: 10.01 \t Val time 0.55\n",
      "Train loss 0.6420 \t Train acc: 0.6304\n",
      "Val loss: 0.6174 \t Val acc: 0.6624\n",
      "Best val acc: 0.6624 at epoch 21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 86.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 24/60 \t Batch 624/625 \t Loss 0.6417 \t Running Acc 0.636 \t Total Acc 0.636 \t Avg Batch Time 0.0116\n",
      "Time: train: 7.26 \t Train loss 0.6417 \t Train acc: 0.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 92.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6206 \t Running Acc 5.234 \t Total Acc 0.662 \t Avg Batch Time 0.0014\n",
      "Epoch 23/60 finished.\n",
      "Train time: 7.26 \t Val time 0.86\n",
      "Train loss 0.6417 \t Train acc: 0.6358\n",
      "Val loss: 0.6169 \t Val acc: 0.6616\n",
      "Best val acc: 0.6624 at epoch 21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 89.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 25/60 \t Batch 624/625 \t Loss 0.6429 \t Running Acc 0.633 \t Total Acc 0.633 \t Avg Batch Time 0.0112\n",
      "Time: train: 7.01 \t Train loss 0.6429 \t Train acc: 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 193.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6196 \t Running Acc 5.285 \t Total Acc 0.668 \t Avg Batch Time 0.0007\n",
      "New best validation model, saving...\n",
      "Epoch 24/60 finished.\n",
      "Train time: 7.01 \t Val time 0.41\n",
      "Train loss 0.6429 \t Train acc: 0.6330\n",
      "Val loss: 0.6159 \t Val acc: 0.6680\n",
      "Best val acc: 0.6680 at epoch 24.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 100.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 26/60 \t Batch 624/625 \t Loss 0.6376 \t Running Acc 0.636 \t Total Acc 0.636 \t Avg Batch Time 0.0099\n",
      "Time: train: 6.20 \t Train loss 0.6376 \t Train acc: 0.6361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 155.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6175 \t Running Acc 5.329 \t Total Acc 0.674 \t Avg Batch Time 0.0008\n",
      "New best validation model, saving...\n",
      "Epoch 25/60 finished.\n",
      "Train time: 6.20 \t Val time 0.51\n",
      "Train loss 0.6376 \t Train acc: 0.6361\n",
      "Val loss: 0.6137 \t Val acc: 0.6736\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 91.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 27/60 \t Batch 624/625 \t Loss 0.6392 \t Running Acc 0.636 \t Total Acc 0.636 \t Avg Batch Time 0.0109\n",
      "Time: train: 6.81 \t Train loss 0.6392 \t Train acc: 0.6360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 195.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6171 \t Running Acc 5.304 \t Total Acc 0.670 \t Avg Batch Time 0.0007\n",
      "Epoch 26/60 finished.\n",
      "Train time: 6.81 \t Val time 0.41\n",
      "Train loss 0.6392 \t Train acc: 0.6360\n",
      "Val loss: 0.6133 \t Val acc: 0.6704\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:08, 73.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 28/60 \t Batch 624/625 \t Loss 0.6399 \t Running Acc 0.635 \t Total Acc 0.635 \t Avg Batch Time 0.0136\n",
      "Time: train: 8.49 \t Train loss 0.6399 \t Train acc: 0.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 105.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6167 \t Running Acc 5.272 \t Total Acc 0.666 \t Avg Batch Time 0.0012\n",
      "Epoch 27/60 finished.\n",
      "Train time: 8.49 \t Val time 0.75\n",
      "Train loss 0.6399 \t Train acc: 0.6353\n",
      "Val loss: 0.6131 \t Val acc: 0.6664\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 89.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 29/60 \t Batch 624/625 \t Loss 0.6397 \t Running Acc 0.636 \t Total Acc 0.636 \t Avg Batch Time 0.0111\n",
      "Time: train: 6.95 \t Train loss 0.6397 \t Train acc: 0.6359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 187.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6162 \t Running Acc 5.285 \t Total Acc 0.668 \t Avg Batch Time 0.0007\n",
      "Epoch 28/60 finished.\n",
      "Train time: 6.95 \t Val time 0.42\n",
      "Train loss 0.6397 \t Train acc: 0.6359\n",
      "Val loss: 0.6124 \t Val acc: 0.6680\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 105.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 30/60 \t Batch 624/625 \t Loss 0.6378 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0094\n",
      "Time: train: 5.90 \t Train loss 0.6378 \t Train acc: 0.6385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 191.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6153 \t Running Acc 5.310 \t Total Acc 0.671 \t Avg Batch Time 0.0007\n",
      "Epoch 29/60 finished.\n",
      "Train time: 5.90 \t Val time 0.42\n",
      "Train loss 0.6378 \t Train acc: 0.6385\n",
      "Val loss: 0.6118 \t Val acc: 0.6712\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 94.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 31/60 \t Batch 624/625 \t Loss 0.6383 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0106\n",
      "Time: train: 6.64 \t Train loss 0.6383 \t Train acc: 0.6377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 170.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6152 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0007\n",
      "Epoch 30/60 finished.\n",
      "Train time: 6.64 \t Val time 0.47\n",
      "Train loss 0.6383 \t Train acc: 0.6377\n",
      "Val loss: 0.6116 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 108.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 32/60 \t Batch 624/625 \t Loss 0.6370 \t Running Acc 0.643 \t Total Acc 0.643 \t Avg Batch Time 0.0092\n",
      "Time: train: 5.76 \t Train loss 0.6370 \t Train acc: 0.6434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 193.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.316 \t Total Acc 0.672 \t Avg Batch Time 0.0007\n",
      "Epoch 31/60 finished.\n",
      "Train time: 5.76 \t Val time 0.41\n",
      "Train loss 0.6370 \t Train acc: 0.6434\n",
      "Val loss: 0.6115 \t Val acc: 0.6720\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 101.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 33/60 \t Batch 624/625 \t Loss 0.6369 \t Running Acc 0.639 \t Total Acc 0.639 \t Avg Batch Time 0.0098\n",
      "Time: train: 6.14 \t Train loss 0.6369 \t Train acc: 0.6395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 136.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.316 \t Total Acc 0.672 \t Avg Batch Time 0.0009\n",
      "Epoch 32/60 finished.\n",
      "Train time: 6.14 \t Val time 0.58\n",
      "Train loss 0.6369 \t Train acc: 0.6395\n",
      "Val loss: 0.6115 \t Val acc: 0.6720\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 96.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 34/60 \t Batch 624/625 \t Loss 0.6404 \t Running Acc 0.641 \t Total Acc 0.641 \t Avg Batch Time 0.0104\n",
      "Time: train: 6.51 \t Train loss 0.6404 \t Train acc: 0.6406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 165.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0008\n",
      "Epoch 33/60 finished.\n",
      "Train time: 6.51 \t Val time 0.48\n",
      "Train loss 0.6404 \t Train acc: 0.6406\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:11, 53.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 35/60 \t Batch 624/625 \t Loss 0.6388 \t Running Acc 0.643 \t Total Acc 0.643 \t Avg Batch Time 0.0185\n",
      "Time: train: 11.59 \t Train loss 0.6388 \t Train acc: 0.6428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 112.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0011\n",
      "Epoch 34/60 finished.\n",
      "Train time: 11.59 \t Val time 0.71\n",
      "Train loss 0.6388 \t Train acc: 0.6428\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:10, 62.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 36/60 \t Batch 624/625 \t Loss 0.6396 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0160\n",
      "Time: train: 10.03 \t Train loss 0.6396 \t Train acc: 0.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:01, 63.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0020\n",
      "Epoch 35/60 finished.\n",
      "Train time: 10.03 \t Val time 1.24\n",
      "Train loss 0.6396 \t Train acc: 0.6378\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:10, 61.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 37/60 \t Batch 624/625 \t Loss 0.6396 \t Running Acc 0.637 \t Total Acc 0.637 \t Avg Batch Time 0.0163\n",
      "Time: train: 10.18 \t Train loss 0.6396 \t Train acc: 0.6374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 183.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0007\n",
      "Epoch 36/60 finished.\n",
      "Train time: 10.18 \t Val time 0.43\n",
      "Train loss 0.6396 \t Train acc: 0.6374\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:09, 62.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 38/60 \t Batch 624/625 \t Loss 0.6374 \t Running Acc 0.640 \t Total Acc 0.640 \t Avg Batch Time 0.0159\n",
      "Time: train: 9.95 \t Train loss 0.6374 \t Train acc: 0.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 146.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0009\n",
      "Epoch 37/60 finished.\n",
      "Train time: 9.95 \t Val time 0.54\n",
      "Train loss 0.6374 \t Train acc: 0.6400\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 78.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 39/60 \t Batch 624/625 \t Loss 0.6382 \t Running Acc 0.639 \t Total Acc 0.639 \t Avg Batch Time 0.0127\n",
      "Time: train: 7.94 \t Train loss 0.6382 \t Train acc: 0.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 146.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0009\n",
      "Epoch 38/60 finished.\n",
      "Train time: 7.94 \t Val time 0.54\n",
      "Train loss 0.6382 \t Train acc: 0.6390\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 78.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 40/60 \t Batch 624/625 \t Loss 0.6392 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0128\n",
      "Time: train: 7.99 \t Train loss 0.6392 \t Train acc: 0.6385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 176.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0007\n",
      "Epoch 39/60 finished.\n",
      "Train time: 7.99 \t Val time 0.45\n",
      "Train loss 0.6392 \t Train acc: 0.6385\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 84.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 41/60 \t Batch 624/625 \t Loss 0.6355 \t Running Acc 0.643 \t Total Acc 0.643 \t Avg Batch Time 0.0119\n",
      "Time: train: 7.44 \t Train loss 0.6355 \t Train acc: 0.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 90.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0014\n",
      "Epoch 40/60 finished.\n",
      "Train time: 7.44 \t Val time 0.87\n",
      "Train loss 0.6355 \t Train acc: 0.6426\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:08, 76.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 42/60 \t Batch 624/625 \t Loss 0.6379 \t Running Acc 0.637 \t Total Acc 0.637 \t Avg Batch Time 0.0131\n",
      "Time: train: 8.22 \t Train loss 0.6379 \t Train acc: 0.6374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 155.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0008\n",
      "Epoch 41/60 finished.\n",
      "Train time: 8.22 \t Val time 0.51\n",
      "Train loss 0.6379 \t Train acc: 0.6374\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 96.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 43/60 \t Batch 624/625 \t Loss 0.6366 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0104\n",
      "Time: train: 6.49 \t Train loss 0.6366 \t Train acc: 0.6382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 198.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0006\n",
      "Epoch 42/60 finished.\n",
      "Train time: 6.49 \t Val time 0.40\n",
      "Train loss 0.6366 \t Train acc: 0.6382\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 85.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 44/60 \t Batch 624/625 \t Loss 0.6398 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0117\n",
      "Time: train: 7.34 \t Train loss 0.6398 \t Train acc: 0.6383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 105.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0012\n",
      "Epoch 43/60 finished.\n",
      "Train time: 7.34 \t Val time 0.75\n",
      "Train loss 0.6398 \t Train acc: 0.6383\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 80.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 45/60 \t Batch 624/625 \t Loss 0.6347 \t Running Acc 0.646 \t Total Acc 0.646 \t Avg Batch Time 0.0124\n",
      "Time: train: 7.76 \t Train loss 0.6347 \t Train acc: 0.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 149.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0008\n",
      "Epoch 44/60 finished.\n",
      "Train time: 7.76 \t Val time 0.53\n",
      "Train loss 0.6347 \t Train acc: 0.6460\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 105.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 46/60 \t Batch 624/625 \t Loss 0.6376 \t Running Acc 0.633 \t Total Acc 0.633 \t Avg Batch Time 0.0095\n",
      "Time: train: 5.95 \t Train loss 0.6376 \t Train acc: 0.6328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 162.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0008\n",
      "Epoch 45/60 finished.\n",
      "Train time: 5.95 \t Val time 0.49\n",
      "Train loss 0.6376 \t Train acc: 0.6328\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 88.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 47/60 \t Batch 624/625 \t Loss 0.6370 \t Running Acc 0.643 \t Total Acc 0.643 \t Avg Batch Time 0.0113\n",
      "Time: train: 7.03 \t Train loss 0.6370 \t Train acc: 0.6430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 119.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0011\n",
      "Epoch 46/60 finished.\n",
      "Train time: 7.03 \t Val time 0.66\n",
      "Train loss 0.6370 \t Train acc: 0.6430\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:07, 80.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 48/60 \t Batch 624/625 \t Loss 0.6387 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0124\n",
      "Time: train: 7.72 \t Train loss 0.6387 \t Train acc: 0.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 222.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0006\n",
      "Epoch 47/60 finished.\n",
      "Train time: 7.72 \t Val time 0.36\n",
      "Train loss 0.6387 \t Train acc: 0.6379\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 117.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 49/60 \t Batch 624/625 \t Loss 0.6377 \t Running Acc 0.640 \t Total Acc 0.640 \t Avg Batch Time 0.0085\n",
      "Time: train: 5.32 \t Train loss 0.6377 \t Train acc: 0.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 198.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0006\n",
      "Epoch 48/60 finished.\n",
      "Train time: 5.32 \t Val time 0.40\n",
      "Train loss 0.6377 \t Train acc: 0.6404\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 99.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 50/60 \t Batch 624/625 \t Loss 0.6363 \t Running Acc 0.636 \t Total Acc 0.636 \t Avg Batch Time 0.0100\n",
      "Time: train: 6.27 \t Train loss 0.6363 \t Train acc: 0.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 176.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0007\n",
      "Epoch 49/60 finished.\n",
      "Train time: 6.27 \t Val time 0.45\n",
      "Train loss 0.6363 \t Train acc: 0.6365\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 109.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 51/60 \t Batch 624/625 \t Loss 0.6393 \t Running Acc 0.641 \t Total Acc 0.641 \t Avg Batch Time 0.0091\n",
      "Time: train: 5.72 \t Train loss 0.6393 \t Train acc: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 215.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0006\n",
      "Epoch 50/60 finished.\n",
      "Train time: 5.72 \t Val time 0.37\n",
      "Train loss 0.6393 \t Train acc: 0.6411\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 116.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 52/60 \t Batch 624/625 \t Loss 0.6384 \t Running Acc 0.636 \t Total Acc 0.636 \t Avg Batch Time 0.0086\n",
      "Time: train: 5.38 \t Train loss 0.6384 \t Train acc: 0.6361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 177.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0007\n",
      "Epoch 51/60 finished.\n",
      "Train time: 5.38 \t Val time 0.45\n",
      "Train loss 0.6384 \t Train acc: 0.6361\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 101.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 53/60 \t Batch 624/625 \t Loss 0.6395 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0098\n",
      "Time: train: 6.15 \t Train loss 0.6395 \t Train acc: 0.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 207.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0006\n",
      "Epoch 52/60 finished.\n",
      "Train time: 6.15 \t Val time 0.38\n",
      "Train loss 0.6395 \t Train acc: 0.6379\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 123.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 54/60 \t Batch 624/625 \t Loss 0.6387 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0081\n",
      "Time: train: 5.06 \t Train loss 0.6387 \t Train acc: 0.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 218.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0006\n",
      "Epoch 53/60 finished.\n",
      "Train time: 5.06 \t Val time 0.36\n",
      "Train loss 0.6387 \t Train acc: 0.6376\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 118.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 55/60 \t Batch 624/625 \t Loss 0.6386 \t Running Acc 0.640 \t Total Acc 0.640 \t Avg Batch Time 0.0084\n",
      "Time: train: 5.26 \t Train loss 0.6386 \t Train acc: 0.6402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 222.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0006\n",
      "Epoch 54/60 finished.\n",
      "Train time: 5.26 \t Val time 0.36\n",
      "Train loss 0.6386 \t Train acc: 0.6402\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 100.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 56/60 \t Batch 624/625 \t Loss 0.6386 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0100\n",
      "Time: train: 6.24 \t Train loss 0.6386 \t Train acc: 0.6385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 183.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0007\n",
      "Epoch 55/60 finished.\n",
      "Train time: 6.24 \t Val time 0.43\n",
      "Train loss 0.6386 \t Train acc: 0.6385\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 115.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 57/60 \t Batch 624/625 \t Loss 0.6375 \t Running Acc 0.642 \t Total Acc 0.642 \t Avg Batch Time 0.0087\n",
      "Time: train: 5.42 \t Train loss 0.6375 \t Train acc: 0.6416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 165.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0008\n",
      "Epoch 56/60 finished.\n",
      "Train time: 5.42 \t Val time 0.48\n",
      "Train loss 0.6375 \t Train acc: 0.6416\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:06, 99.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 58/60 \t Batch 624/625 \t Loss 0.6392 \t Running Acc 0.637 \t Total Acc 0.637 \t Avg Batch Time 0.0101\n",
      "Time: train: 6.30 \t Train loss 0.6392 \t Train acc: 0.6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 141.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0009\n",
      "Epoch 57/60 finished.\n",
      "Train time: 6.30 \t Val time 0.56\n",
      "Train loss 0.6392 \t Train acc: 0.6375\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 110.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 59/60 \t Batch 624/625 \t Loss 0.6377 \t Running Acc 0.638 \t Total Acc 0.638 \t Avg Batch Time 0.0090\n",
      "Time: train: 5.64 \t Train loss 0.6377 \t Train acc: 0.6383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 164.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0008\n",
      "Epoch 58/60 finished.\n",
      "Train time: 5.64 \t Val time 0.48\n",
      "Train loss 0.6377 \t Train acc: 0.6383\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:05, 108.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> train \t Epoch 60/60 \t Batch 624/625 \t Loss 0.6379 \t Running Acc 0.641 \t Total Acc 0.641 \t Avg Batch Time 0.0093\n",
      "Time: train: 5.78 \t Train loss 0.6379 \t Train acc: 0.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 194.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> val \t Loss 0.6151 \t Running Acc 5.323 \t Total Acc 0.673 \t Avg Batch Time 0.0006\n",
      "Epoch 59/60 finished.\n",
      "Train time: 5.78 \t Val time 0.41\n",
      "Train loss 0.6379 \t Train acc: 0.6413\n",
      "Val loss: 0.6115 \t Val acc: 0.6728\n",
      "Best val acc: 0.6736 at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:00, 167.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> test \t Loss 0.6185 \t Running Acc 5.266 \t Total Acc 0.666 \t Avg Batch Time 0.0008\n",
      "Final  tensor([[1.0000, 0.5711, 0.4289],\n",
      "        [0.0000, 0.4900, 0.5100],\n",
      "        [0.0000, 0.2934, 0.7066],\n",
      "        ...,\n",
      "        [0.0000, 0.4876, 0.5124],\n",
      "        [0.0000, 0.6398, 0.3602],\n",
      "        [0.0000, 0.3992, 0.6008]], device='cuda:0', dtype=torch.float64)\n",
      "Test: Loss 0.6178 \t Acc 0.6656 \t AUC: 0.7226 \t 1/eB 0.3: 13.8864 \t 1/eB 0.5: 5.5045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    N_EPOCHS = 60\n",
    "\n",
    "    # put your model and log path here.\n",
    "    model_path = \"../models/LieEQGNN/\"\n",
    "    log_path = \"../logs/LieEQGNN/\"\n",
    "\n",
    "    ### set random seed\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ### initialize cuda\n",
    "    device = 'cuda' #torch.device(\"cuda\")\n",
    "    dtype = torch.float64\n",
    "\n",
    "    model = LieEQGNN(n_scalar = 1, n_hidden = 4, n_class = 2,\\\n",
    "                       dropout = 0.2, n_layers = 1,\\\n",
    "                       c_weight = 1e-3).to(device, dtype)\n",
    "\n",
    "    ### print model and dataset information\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"Model Size:\", pytorch_total_params)\n",
    "    for (split, dataloader) in dataloaders.items():\n",
    "        print(f\" {split} samples: {len(dataloader.dataset)}\")\n",
    "\n",
    "    ### optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "    ### lr scheduler\n",
    "    base_scheduler = CosineAnnealingWarmRestarts(optimizer, 4, 2)\n",
    "    lr_scheduler = GradualWarmupScheduler(optimizer, multiplier=1,\\\n",
    "                                                warmup_epoch=5,\\\n",
    "                                                after_scheduler=base_scheduler) ## warmup\n",
    "\n",
    "    ### loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    ### initialize logs\n",
    "    res = {'epochs': [], 'lr' : [],\\\n",
    "           'train_time': [], 'val_time': [],  'train_loss': [], 'val_loss': [],\\\n",
    "           'train_acc': [], 'val_acc': [], 'best_val': 0, 'best_epoch': 0}\n",
    "\n",
    "    ### training and testing\n",
    "    print(\"Training...\")\n",
    "    train(model, res, N_EPOCHS, model_path, log_path)\n",
    "    test(model, res, model_path, log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(log_path) as f:\n",
    "\n",
    "    data = json.load(f)\n",
    "    epochs = data[\"epochs\"]\n",
    "    train_loss = data[\"train_loss\"]\n",
    "    val_loss = data[\"val_loss\"]\n",
    "    train_acc = data[\"train_acc\"]\n",
    "    val_acc = data[\"val_acc\"]\n",
    "    \n",
    "    # Plotting Loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epochs, train_loss, label='Train Loss', color='blue', linestyle='--')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss', color='blue', linestyle='-')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(model_name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting Accuracy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(epochs, train_acc, label='Train Accuracy', color='green', linestyle='--')\n",
    "    plt.plot(epochs, val_acc, label='Validation Accuracy', color='green', linestyle='-')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(model_name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Neto, Jogi Suda, et al. \"[Lie-Equivariant Quantum Graph Neural Networks.](https://arxiv.org/abs/2411.15315)\" arXiv preprint arXiv:2411.15315 (2024).\n",
    "\n",
    "[2] Shlomi, et al. \"[Graph neural networks in particle physics.](https://arxiv.org/abs/2007.13681)\" Machine Learning: Science and Technology 2.2 (2020): 021001.\n",
    "\n",
    "[2] Jonas M. Kübler, et al. \"[The inductive bias of quantum kernels](https://proceedings.neurips.cc/paper/2021/file/69adc1e107f7f7d035d7baf04342e1ca-Paper.pdf)\", 2021.\n",
    "\n",
    "[3] Jarrod R. McClean, et al. \"[Barren plateaus in quantum neural network training landscapes](https://www.nature.com/articles/s41467-018-07090-4)\". Nature Communications, 9(1), November 2018.\n",
    "\n",
    "[4] M. Cerezo, et al. \"[Cost function dependent barren plateaus in shallow parametrized quantum circuits](https://www.nature.com/articles/s41467-021-21728-w)\". Nature Communications, 12(1), March 2021.\n",
    "\n",
    "[5] Tüysüz, Cenk, et al. \"[Symmetry breaking in geometric quantum machine learning in the presence of noise.](https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.5.030314)\" PRX Quantum 5.3 (2024): 030314.\n",
    "\n",
    "[5] Forestano, Roy T., et al. \"[Deep learning symmetries and their Lie groups, algebras, and subalgebras from first principles.](https://arxiv.org/abs/2301.05638)\" Machine Learning: Science and Technology 4.2 (2023): 025027.\n",
    "\n",
    "[6] Gong, S., et al. \"An Efficient Lorentz Equivariant Graph Neural Network for Jet Tagging\" [arXiv:2201.08187](https://arxiv.org/abs/2201.08187).\n",
    "\n",
    "[7] Komiske, P. T., Metodiev, E. M., & Thaler, J. \"EnergyFlow: A Python Package for High Energy Physics.\" [EnergyFlow](https://energyflow.network/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML (QiBO)",
   "language": "python",
   "name": "qml_qibo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
